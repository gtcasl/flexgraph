\section{Introduction}

The end of Dennard Scaling \cite{Dark-Silicon} has moved the focus of computer architecture designers towards power and energy efficient architectures. However, energy efficient solutions such as ASIC designs present a serious limitation in flexibility and production cycle. These constraints have pushed production data centers towards using FPGA-based accelerators \cite{Catapult} for their reconfigurability and energy savings when compared to general-purpose graphics processing units (GPUs).
This trend has led to emergence of heterogeneous CPU-FPGA computing platforms \cite{Intel-FPGA} \cite{IBM-FPGA}, enabling fast development of new energy efficient accelerators \cite{CPU-FPGA} for domain specific applications. Graph Analytics is one the largest applications in production data centers today \cite{BigData}, 
spanning domains such as bio-informatics, social network, mining, cyber-security, etc. Graph Analytics performance suffers from workload imbalance, frequent updates, limited data locality and low compute communication ratio making it memory-bound and energy inefficient. This problem is further exacerbated with the ever increasing size of its dataset, presenting a scalability challenge for the industry. Several solutions have been proposed to address this problem both at the software level, with better algorithms and programming abstraction \cite{GraphX} \cite{Galois} \cite{GraphMat} \cite{Pregel} \cite{GraphLab}, and at the hardware level with custom accelerators \cite {Graphicionado} \cite{Tesseract} \cite{GraphOps}. Most Graph Analytics accelerators \cite {Graphicionado} \cite{Tesseract} \cite{GraphOps} define a proprietary graph data structure to exploit efficient computation on their hardware, limiting flexibility on the host processor for efficient software processing. FlexGraph uses sparse matrices as underlying data structure to enable efficient computation in a shared CPU-FPGA environment where both the host processor and the accelerator are modifying the same graph. However, accessing unstructured fine-grained data on a cache coherent FPGA fabric pauses challenges because of the restricted coarse-grained cache line access granularity and longer miss penalty. Additionally, generalized sparse matrix storage encoding COO, ELL, CSR, CSC, lack the same level of compaction as directly using non-zero edges list \cite {Graphicionado}, pausing a problem for energy efficiency and memory bandwidth for hyper-sparse Graph Analytics application. FlexGraph uses a Doubly Compressed Column Based Sparse matrix encoding similar to GraphMath \cite{GraphMat}, however introducing additional indirections to the matrix traversal path. We decoupled FlexGraph's matrix traversal unit from the rest of the compute and memory fabric to scaling by increasing memory bandwidth and provide support for other formats without altering the rest of the system.\\
Our contributions are as follows:\\
1.	A specialized Graph Analytics Accelerator for heterogeneous CPU-FPGA fabric that provide efficient collaborative computation while maximizing energy efficiency.\\
2. 	A decoupled data structure traversal and compute architecture for sparse matrices enabling maximum bandwidth utilization and compute scaling.\\
3.	We introduce hardware primitives for unstructured fine-grained accesses on coherent shared memory architectures.\\
4. 	A Doubly-Compressed Sparse Matrix-Sparse Vector Multiplication Accelerator implementation on FPGA. 
5. 	A domain specific accelerator with single source programming and reconfiguration environment providing a design-efficient alternative to High-Level Synthesis.  

The remainder of this paper is organized as follows:
Section 2 provides a background and motivation for the FlexGrah accelerator, section 3 describes FlexGraph's architecture, section 4 describe FlexGraph's software-hardware codesign using Cash \cite{Cash} framework, section 5 describes the experimental setup, section 6 describes our results analysis, section 7 describes the related work, section 8 summarizes our main contribution and results.